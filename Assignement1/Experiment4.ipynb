{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4\n",
    "- Load the saved model and replace the output layer of the model, as well as the two last convolutional layers.\n",
    "- Train and evaluate the model on the cats and dogs dataset.\n",
    "\n",
    "## Steps\n",
    "- Load the saved model using keras.models.load_model().\n",
    "- Freeze all layers except the output layer and the last two convolutional layers.\n",
    "- Replace the output layer to match the number of classes (num_classes = 2 for cats vs. dogs).\n",
    "- Retrain the model on the Cats vs. Dogs dataset.\n",
    "\n",
    "### Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import data as tf_data\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Load the pre-trained model\n",
    "saved_model_path = \"models/experiment1_model.keras\"\n",
    "model = keras.models.load_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the model\n",
    "See which layer need to be reset, in our case 23 to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: input_layer_1\n",
      "Layer 1: rescaling_1\n",
      "Layer 2: conv2d_4\n",
      "Layer 3: batch_normalization_8\n",
      "Layer 4: activation_8\n",
      "Layer 5: activation_9\n",
      "Layer 6: separable_conv2d_7\n",
      "Layer 7: batch_normalization_9\n",
      "Layer 8: activation_10\n",
      "Layer 9: separable_conv2d_8\n",
      "Layer 10: batch_normalization_10\n",
      "Layer 11: max_pooling2d_3\n",
      "Layer 12: conv2d_5\n",
      "Layer 13: add_3\n",
      "Layer 14: activation_11\n",
      "Layer 15: separable_conv2d_9\n",
      "Layer 16: batch_normalization_11\n",
      "Layer 17: activation_12\n",
      "Layer 18: separable_conv2d_10\n",
      "Layer 19: batch_normalization_12\n",
      "Layer 20: max_pooling2d_4\n",
      "Layer 21: conv2d_6\n",
      "Layer 22: add_4\n",
      "Layer 23: activation_13\n",
      "Layer 24: separable_conv2d_11\n",
      "Layer 25: batch_normalization_13\n",
      "Layer 26: activation_14\n",
      "Layer 27: separable_conv2d_12\n",
      "Layer 28: batch_normalization_14\n",
      "Layer 29: max_pooling2d_5\n",
      "Layer 30: conv2d_7\n",
      "Layer 31: add_5\n",
      "Layer 32: separable_conv2d_13\n",
      "Layer 33: batch_normalization_15\n",
      "Layer 34: activation_15\n",
      "Layer 35: global_average_pooling2d_1\n",
      "Layer 36: dropout_1\n",
      "Layer 37: dense_1\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for layer in model.layers:\n",
    "    print(f\"Layer {i}: {layer.name}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        units = 1\n",
    "    else:\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    # Change output layer for multi-class classification (120 dog breeds)\n",
    "    outputs = layers.Dense(units, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh model with the same architecture\n",
    "fresh_model = make_model(input_shape=(180, 180) + (3,), num_classes=1)\n",
    "base_model = keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "base_model.trainable = False \n",
    "\n",
    "# Reset weights for layers 6 to 22\n",
    "for i in range(23, 31):\n",
    "    base_model.layers[i].set_weights(fresh_model.layers[i].get_weights())\n",
    "    base_model.layers[i].trainable = True  # Make sure the layers are trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new output layer (Binary Classification)\n",
    "new_output = layers.Dense(1, activation=\"sigmoid\")(base_model.output)\n",
    "\n",
    "# Create a new model\n",
    "new_model = keras.Model(inputs=base_model.input, outputs=new_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Modification for experiment 1\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23422 files belonging to 2 classes.\n",
      "Using 18738 files for training.\n",
      "Using 4684 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "image_size = (180, 180)\n",
    "batch_size = 128\n",
    "\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    \"PetImages\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "data_augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "\n",
    "def data_augmentation(images):\n",
    "    for layer in data_augmentation_layers:\n",
    "        images = layer(images)\n",
    "    return images\n",
    "\n",
    "augmented_train_ds = train_ds.map(\n",
    "    lambda x, y: (data_augmentation(x), y))\n",
    "\n",
    "# Apply `data_augmentation` to the training images.\n",
    "train_ds = train_ds.map(\n",
    "    lambda img, label: (data_augmentation(img), label),\n",
    "    num_parallel_calls=tf_data.AUTOTUNE,\n",
    ")\n",
    "# Prefetching samples in GPU memory helps maximize GPU utilization.\n",
    "train_ds = train_ds.prefetch(tf_data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf_data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utilisateur\\Documents\\GitHub\\DL_Assignements\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:780: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 2s/step - acc: 0.6407 - loss: 0.6281 - val_acc: 0.5160 - val_loss: 0.6927\n",
      "Epoch 2/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 2s/step - acc: 0.7361 - loss: 0.5197 - val_acc: 0.5942 - val_loss: 0.6471\n",
      "Epoch 3/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 2s/step - acc: 0.7713 - loss: 0.4751 - val_acc: 0.6302 - val_loss: 0.6205\n",
      "Epoch 4/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.7867 - loss: 0.4445 - val_acc: 0.7248 - val_loss: 0.5330\n",
      "Epoch 5/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 2s/step - acc: 0.8080 - loss: 0.4203 - val_acc: 0.7718 - val_loss: 0.4644\n",
      "Epoch 6/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 2s/step - acc: 0.8167 - loss: 0.4013 - val_acc: 0.8187 - val_loss: 0.4091\n",
      "Epoch 7/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 2s/step - acc: 0.8239 - loss: 0.3865 - val_acc: 0.8337 - val_loss: 0.3799\n",
      "Epoch 8/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 2s/step - acc: 0.8308 - loss: 0.3755 - val_acc: 0.8382 - val_loss: 0.3738\n",
      "Epoch 9/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 2s/step - acc: 0.8401 - loss: 0.3571 - val_acc: 0.8230 - val_loss: 0.4004\n",
      "Epoch 10/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 2s/step - acc: 0.8421 - loss: 0.3525 - val_acc: 0.8424 - val_loss: 0.3759\n",
      "Epoch 11/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 2s/step - acc: 0.8542 - loss: 0.3351 - val_acc: 0.7923 - val_loss: 0.4388\n",
      "Epoch 12/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 2s/step - acc: 0.8546 - loss: 0.3309 - val_acc: 0.8442 - val_loss: 0.3597\n",
      "Epoch 13/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 2s/step - acc: 0.8553 - loss: 0.3263 - val_acc: 0.8420 - val_loss: 0.3727\n",
      "Epoch 14/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 2s/step - acc: 0.8647 - loss: 0.3152 - val_acc: 0.8249 - val_loss: 0.3995\n",
      "Epoch 15/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 2s/step - acc: 0.8649 - loss: 0.3073 - val_acc: 0.8328 - val_loss: 0.3847\n",
      "Epoch 16/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 2s/step - acc: 0.8721 - loss: 0.3008 - val_acc: 0.8621 - val_loss: 0.3317\n",
      "Epoch 17/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 2s/step - acc: 0.8755 - loss: 0.2958 - val_acc: 0.8553 - val_loss: 0.3288\n",
      "Epoch 18/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 2s/step - acc: 0.8735 - loss: 0.2906 - val_acc: 0.8484 - val_loss: 0.3458\n",
      "Epoch 19/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 2s/step - acc: 0.8812 - loss: 0.2783 - val_acc: 0.8659 - val_loss: 0.3150\n",
      "Epoch 20/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 2s/step - acc: 0.8796 - loss: 0.2794 - val_acc: 0.8593 - val_loss: 0.3215\n",
      "Epoch 21/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.8845 - loss: 0.2728 - val_acc: 0.8427 - val_loss: 0.3629\n",
      "Epoch 22/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.8855 - loss: 0.2704 - val_acc: 0.8691 - val_loss: 0.3078\n",
      "Epoch 23/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.8890 - loss: 0.2633 - val_acc: 0.8531 - val_loss: 0.3359\n",
      "Epoch 24/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.8942 - loss: 0.2534 - val_acc: 0.8531 - val_loss: 0.3346\n",
      "Epoch 25/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.8948 - loss: 0.2539 - val_acc: 0.8610 - val_loss: 0.3202\n",
      "Epoch 26/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.8957 - loss: 0.2513 - val_acc: 0.8542 - val_loss: 0.3326\n",
      "Epoch 27/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.8983 - loss: 0.2422 - val_acc: 0.8290 - val_loss: 0.3777\n",
      "Epoch 28/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.8975 - loss: 0.2398 - val_acc: 0.8678 - val_loss: 0.3108\n",
      "Epoch 29/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.8975 - loss: 0.2400 - val_acc: 0.7675 - val_loss: 0.5246\n",
      "Epoch 30/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.9011 - loss: 0.2380 - val_acc: 0.8815 - val_loss: 0.2835\n",
      "Epoch 31/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.9020 - loss: 0.2332 - val_acc: 0.8550 - val_loss: 0.3237\n",
      "Epoch 32/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.9089 - loss: 0.2247 - val_acc: 0.8764 - val_loss: 0.2922\n",
      "Epoch 33/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.9051 - loss: 0.2271 - val_acc: 0.8687 - val_loss: 0.2985\n",
      "Epoch 34/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - acc: 0.9113 - loss: 0.2160 - val_acc: 0.8834 - val_loss: 0.2741\n",
      "Epoch 35/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 2s/step - acc: 0.9102 - loss: 0.2170 - val_acc: 0.8826 - val_loss: 0.2709\n",
      "Epoch 36/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 2s/step - acc: 0.9124 - loss: 0.2132 - val_acc: 0.8640 - val_loss: 0.3240\n",
      "Epoch 37/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9079 - loss: 0.2231 - val_acc: 0.8836 - val_loss: 0.2739\n",
      "Epoch 38/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9154 - loss: 0.2060 - val_acc: 0.8713 - val_loss: 0.3003\n",
      "Epoch 39/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9160 - loss: 0.2034 - val_acc: 0.8416 - val_loss: 0.3613\n",
      "Epoch 40/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9164 - loss: 0.2029 - val_acc: 0.8856 - val_loss: 0.2733\n",
      "Epoch 41/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9199 - loss: 0.1953 - val_acc: 0.8851 - val_loss: 0.2729\n",
      "Epoch 42/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9198 - loss: 0.1974 - val_acc: 0.7869 - val_loss: 0.4958\n",
      "Epoch 43/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9225 - loss: 0.1916 - val_acc: 0.8864 - val_loss: 0.2727\n",
      "Epoch 44/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9200 - loss: 0.1934 - val_acc: 0.8420 - val_loss: 0.3752\n",
      "Epoch 45/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9223 - loss: 0.1886 - val_acc: 0.8674 - val_loss: 0.3263\n",
      "Epoch 46/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9279 - loss: 0.1822 - val_acc: 0.8215 - val_loss: 0.4333\n",
      "Epoch 47/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9280 - loss: 0.1812 - val_acc: 0.8824 - val_loss: 0.2778\n",
      "Epoch 48/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9309 - loss: 0.1721 - val_acc: 0.8792 - val_loss: 0.2816\n",
      "Epoch 49/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9293 - loss: 0.1760 - val_acc: 0.8572 - val_loss: 0.3488\n",
      "Epoch 50/50\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - acc: 0.9313 - loss: 0.1746 - val_acc: 0.8928 - val_loss: 0.2584\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(filepath=\"models/experiment4_epoch_{epoch}.keras\")\n",
    "]\n",
    "\n",
    "new_model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "new_model.save(\"experiment4_model.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
