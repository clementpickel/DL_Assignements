{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc40c85",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a03a7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import glob\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 6)\n",
    "pd.set_option(\"display.max_rows\", 6)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d47af",
   "metadata": {},
   "source": [
    "## Get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb4c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_files = glob.glob(os.path.join(\"dataset\", \"*.edges\"))\n",
    "node_files = glob.glob(os.path.join(\"dataset\", \"*.nodes\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea80240",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d85a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_dfs = []\n",
    "for file_path in edge_files:\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep=\", \",\n",
    "        header=None,\n",
    "        names=[\"target\", \"source\"]\n",
    "    )\n",
    "    edge_dfs.append(df)\n",
    "\n",
    "node_dfs = []\n",
    "for file_path in node_files:\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep=\",\",\n",
    "        header=None,\n",
    "        names=[\"node id\", \"current x\", \"current y\", \"previous x\", \"previous y\", \"future x\", \"future y\"],\n",
    "        na_values=\"_\"\n",
    "    )\n",
    "    node_dfs.append(df)\n",
    "\n",
    "edges = pd.concat(edge_dfs, ignore_index=True)\n",
    "nodes = pd.concat(node_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cda7445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        target    source\n",
      "0     19585800  19590700\n",
      "1     19585800  19595200\n",
      "2     19590700  19592400\n",
      "...        ...       ...\n",
      "3456  19592800        -1\n",
      "3457  20014600        -1\n",
      "3458  20015100        -1\n",
      "\n",
      "[3459 rows x 2 columns]\n",
      "       node id  current x  current y  ...  previous y  future x  future y\n",
      "0     19502500    40972.0   -16957.0  ...    -16957.0   41185.0  -16480.0\n",
      "1     19585800    12688.0    -6816.0  ...     -6816.0   13381.0   -7427.0\n",
      "2     19590400   -16367.0    21644.0  ...     21644.0       NaN       NaN\n",
      "...        ...        ...        ...  ...         ...       ...       ...\n",
      "2306  20015100   -19196.0     3668.0  ...      3041.0  -19196.0    3668.0\n",
      "2307  20015600    17568.0   -13258.0  ...    -14736.0   17568.0  -13258.0\n",
      "2308  20015900    16994.0   -12152.0  ...         NaN   16994.0  -12152.0\n",
      "\n",
      "[2309 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(edges)\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487439ec",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8beca6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain random indices\n",
    "random_indices = np.random.permutation(range(nodes.shape[0]))\n",
    "\n",
    "# 50/50 split\n",
    "train_data = nodes.iloc[random_indices[: len(random_indices) // 2]]\n",
    "test_data = nodes.iloc[random_indices[len(random_indices) // 2 :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43a90b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       node id  current x  current y  ...  previous y  future x  future y\n",
      "322   19585800    15484.0    -9938.0  ...     -8963.0   16229.0  -10621.0\n",
      "1734  20002900    34808.0   -22367.0  ...    -22301.0   34858.0  -22511.0\n",
      "1447  20002900    34478.0   -21915.0  ...    -22065.0   34414.0  -22177.0\n",
      "...        ...        ...        ...  ...         ...       ...       ...\n",
      "1187  19595300    30636.0   -16351.0  ...    -16060.0   31589.0  -16622.0\n",
      "1480  19595300    37002.0   -18290.0  ...    -18035.0   38039.0  -18755.0\n",
      "1755  19595800    41817.0   -21716.0  ...    -20817.0   42670.0  -22344.0\n",
      "\n",
      "[1154 rows x 7 columns]\n",
      "       node id  current x  current y  ...  previous y  future x  future y\n",
      "1823  20000700    40022.0   -18541.0  ...    -18926.0   41085.0  -18375.0\n",
      "812   20001100    47054.0   -19951.0  ...    -20969.0       NaN       NaN\n",
      "1316  20001800    34571.0   -18728.0  ...    -18346.0   35204.0  -19160.0\n",
      "...        ...        ...        ...  ...         ...       ...       ...\n",
      "1618  20001800    38911.0   -20702.0  ...    -20253.0   39683.0  -21053.0\n",
      "1272  19595300    33432.0   -17480.0  ...    -16914.0   34480.0  -17552.0\n",
      "855   19502500    40113.0   -16625.0  ...    -16714.0   40377.0  -16993.0\n",
      "\n",
      "[1155 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1647801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current x     float32\n",
      "current y     float32\n",
      "previous x    float32\n",
      "previous y    float32\n",
      "future x      float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(nodes.sort_values(\"node id\").iloc[:, 1:-1].astype(np.float32).dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd223d28",
   "metadata": {},
   "source": [
    "## Prepare the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ad5c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges shape:\t\t (3459, 2)\n",
      "Node features shape: (2309, 5)\n"
     ]
    }
   ],
   "source": [
    "# Obtain paper indices which will be used to gather node states\n",
    "# from the graph later on when training the model\n",
    "train_indices = train_data[\"node id\"].to_numpy()\n",
    "test_indices = test_data[\"node id\"].to_numpy()\n",
    "\n",
    "# Obtain ground truth labels corresponding to each paper_id\n",
    "train_labels = train_data[[\"future x\", \"future y\"]].to_numpy()\n",
    "test_labels = test_data[[\"future x\", \"future y\"]].to_numpy()\n",
    "\n",
    "# Define graph, namely an edge tensor and a node feature tensor\n",
    "edges = tf.convert_to_tensor(edges[[\"target\", \"source\"]])\n",
    "node_states = tf.convert_to_tensor(nodes.sort_values(\"node id\").iloc[:, 1:-1])\n",
    "\n",
    "# Print shapes of the graph\n",
    "print(\"Edges shape:\\t\\t\", edges.shape)\n",
    "print(\"Node features shape:\", node_states.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
